required_resources:
   deberta-v3-large:  "s3://ANONYMOUS/deberta-v3-large"
   huggingface: "s3://ANONYMOUS/huggingface"
   ner: "s3://ANONYMOUS/ner"
remote_zoo_dir: "s3://ANONYMOUS/local_models_zoo"
load_from_zoo_use_remote: false
resource_dir: "resources"
push_to_remote_zoo: false
push_to_local_zoo: true

evaluate_locals_ood_after_merge: false
evaluate_locals_before: true
evaluate_locals_after: false

merger:
  enabled: false

seed: "{seed}"
main_output_dir: 'runs/ner-deberta-large/mtl-new-lr1e-5-seed{seed}'
default_model_args:
  model_name: "{resource_dir}/deberta-v3-large"
  version: "hyp0918"
  zoo_filter:
    version: "hyp0918"
    seed: "{seed}"
  do_lower_case: false
  per_device_train_batch_size: 16
  lr_scheduler_type: "polynomial"
  warmup_ratio: 0.06
  learning_rate: 1.0e-5
  num_train_epochs: 20.0
  #adam_beta1: 0.9
  #adam_beta2: 0.98
  #adam_epsilon: 1.0e-6
  #max_grad_norm: 0.0
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  #eval_steps: 10
  load_best_model_at_end: true
  metric_for_best_model: "key_score"
  reweight_loss_schema: "sqrt"
tokenizer: "{resource_dir}/deberta-v3-large"
model_type: deberta
