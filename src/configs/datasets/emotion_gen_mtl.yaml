main_output_dir: 'runs/emotion_debug'
load_from_zoo: "no"

evaluate_locals_before: true
evaluate_locals_after: true
evaluate_global_model: false
evaluate_locals_ood: false
evaluate_global_joint: false

eval_on_test: true

seq2seq: true

mtl: true
mtl_all_tasks: true
mtl_shared_label_space: true

templates:
  dataset: "emotion"
_mtl_models: {} # this will be 'models' after preprocess

ood_datasets:
  ood0:
    dataset_name: emoint
  ood1:
    dataset_name: ssec
  ood2:
    dataset_name: electoraltweets
  ood3:
    dataset_name: grounded_emotions
  ood4:
    dataset_name: affectivetext
  ood5:
    dataset_name: "dailydialog"
    test_only: true
  ood6:
    dataset_name: "crowdflower"
    test_only: true
  ood7:
    dataset_name: "tec"
    test_only: true
  ood8:
    dataset_name: "tales-emotion"
    test_only: true
  ood9:
    dataset_name: "isear"
    test_only: true

ood_all_is_test: true

local_models:
  output_dir_format: '{main_output_dir}/local_models/{name}'
  models:
      model0:
        dataset_name: "dailydialog"
      model1:
        dataset_name: "crowdflower"
      model2:
        dataset_name: "tec"
      model3:
        dataset_name: "tales-emotion"
      model4:
        dataset_name: "emobank"
      model5:
        dataset_name: "isear"
      model6:
        dataset_name: "emoint"
      model7:
        dataset_name: "ssec"
      model8:
        dataset_name: "electoraltweets"
      model9:
        dataset_name: "fb-valence-arousal-anon"
      model10:
        dataset_name: "grounded_emotions"
      model11:
        dataset_name: "emotion-cause"
      model12:
        dataset_name: "affectivetext"

merger:
  exclude_param_regex: []
  multi_label_head_special: false

tokenizer: "{resource_dir}/distilbert-base-uncased"
model_type: distilbert

# for debug


global_device: 'cuda:0'
dataset: "{dataset}"
partition_method: "uniform"


# from fednlp: model_args
default_model_args:
  # just for debugging
  is_regression: false
  task_type: "multi_label"
  num_train_epochs: 3.0
  do_lower_case: true
  per_device_eval_batch_size: 32
  fp16: false
  gradient_accumulation_steps: 1
  learning_rate: 2.0e-5
  local_rank: -1
  max_grad_norm: 1.0
  max_seq_length: 128
  model_type: null
  save_total_limit: 2
  max_steps: -1
  per_device_train_batch_size: 32
  use_multiprocessing: false # dataloader
  labels_map: {}
  regression: false
  version: 0
  partition: -1
  device: 'cuda:0'
  include_inputs_for_metrics: true
