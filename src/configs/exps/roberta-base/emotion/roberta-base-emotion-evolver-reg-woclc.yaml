required_resources:
   roberta-base:  "s3://ANONYMOUS/roberta-base"
   huggingface: "s3://ANONYMOUS/huggingface"
   emotion_splits: "s3://ANONYMOUS/emotion_splits"
remote_zoo_dir: "s3://ANONYMOUS/local_models_zoo"
load_from_zoo_use_remote: false
resource_dir: "resources"
push_to_remote_zoo: false
push_to_local_zoo: true

evolver:
  enabled: true
  with_merger: true
  f: 0.5
  # f: 0.8
  cr_max: 0.5
  cr_min: 0.5
  max_iters: 15
  resume_global: false
  save_global: true

merger:
  regmean_exclude_param_regex: ['.*classifier.*']
  # regmean_exclude_param_regex: []
  regmean_mean: true
  gram_n_example: 1000
  gram_version: "h_1000_0726_fix_without_classifier"
  regmean_reduce_nondiag: 0.1

evaluate_locals_ood_after_merge: true
evaluate_locals_before: false
evaluate_locals_after: true
evaluate_global_model: false

seed: "{seed}"
main_output_dir: '/data/guodong/nlp/runs/emotion-roberta_base/evolver-reg-woclc2_cr0.5_f0.5_g15/seed{seed}'
default_model_args:
  model_name: "{resource_dir}/roberta-base"
  version: "hyp0812"
  zoo_filter:
    version: "hyp0812"
    seed: "{seed}"
  do_lower_case: false
  per_device_train_batch_size: 16
  lr_scheduler_type: "polynomial"
  warmup_ratio: 0.06
  learning_rate: 1.0e-5
  num_train_epochs: 30.0
  #adam_beta1: 0.9
  #adam_beta2: 0.98
  #adam_epsilon: 1.0e-6
  #max_grad_norm: 0.0
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  load_best_model_at_end: true
  metric_for_best_model: "key_score"
tokenizer: "{resource_dir}/roberta-base"
model_type: roberta-base
